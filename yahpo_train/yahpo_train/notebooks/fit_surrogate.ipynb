{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from yahpo_train.model  import *\n",
                "from yahpo_train.metrics import *\n",
                "from yahpo_train.cont_scalers import *\n",
                "from yahpo_gym.benchmarks import lcbench, rbv2, nasbench_301, fcnet, taskset\n",
                "from yahpo_gym.configuration import cfg\n",
                "from fastai.callback.wandb import *\n",
                "from functools import partial"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training a surrogate:\n",
                "\n",
                "We provide a function `fit_config` that allows for training a surrogate with a set of hyperparameters and the option to export the surrogate (this can overwrite existing surrogates!).\n",
                "\n",
                "A particularity is that we use a set of so called `ContTransformers` in order to transfer continuous variables to a scale better suited for optimization! \n",
                "This has a strong effect on the resulting performance and should therefore be optimized!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fit_config(key, embds_dbl=None, embds_tgt=None, tfms=None, lr = 1e-4, epochs=25, deep=[512,512,256], deeper=[], dropout=0., wide=True, use_bn=False, frac=1.0, bs=2048, export=False):\n",
                "    \"\"\"\n",
                "    Fit function with hyperparameters\n",
                "    \"\"\"\n",
                "    cc = cfg(key)\n",
                "    dls = dl_from_config(cc, bs=bs, frac=frac)\n",
                "\n",
                "    # Construct embds from transforms. tfms overwrites emdbs_dbl, embds_tgt\n",
                "    if tfms is not None:\n",
                "        embds_dbl = [tfms.get(name) if tfms.get(name) is not None else ContTransformerNone for name, cont in dls.all_cols[dls.cont_names].iteritems()]\n",
                "        embds_tgt = [tfms.get(name) if tfms.get(name) is not None else ContTransformerNone for name, cont in dls.ys.iteritems()]\n",
                "\n",
                "    # Instantiate learner\n",
                "    f = FFSurrogateModel(dls, layers=deep, deeper=deeper, ps=dropout, use_bn = use_bn, wide=wide, embds_dbl=embds_dbl, embds_tgt=embds_tgt)\n",
                "    l = SurrogateTabularLearner(dls, f, loss_func=nn.MSELoss(reduction='mean'), metrics=nn.MSELoss)\n",
                "    l.metrics = [AvgTfedMetric(mae),  AvgTfedMetric(r2), AvgTfedMetric(spearman)]\n",
                "    l.add_cb(MixHandler)\n",
                "    l.add_cb(EarlyStoppingCallback(patience=3))\n",
                "\n",
                "    # Fit\n",
                "    l.fit_flat_cos(epochs, lr)\n",
                "\n",
                "    if export:\n",
                "        l.export_onnx(cc)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example\n",
                "\n",
                "Find an example for training the `NASBENCH 301` surrogate below:\n",
                "\n",
                "We supply a list of `ContTransformer`'s to our `fit_config` function that define the specific transformers that should be applied for this scenario:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def fit_nb301(key = 'nb301', **kwargs):\n",
                "    embds_dbl = [partial(ContTransformerMultScalar, m = 1/52)]\n",
                "    embds_tgt = [partial(ContTransformerMultScalar, m = 1/100), ContTransformerRange]\n",
                "    fit_config(key, embds_dbl=embds_dbl, embds_tgt=embds_tgt, **kwargs)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example\n",
                "\n",
                "A more involved example is the `rbv2_super` surrogate, where multiple different transformers are used depending on the input and output variables.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def fit_rbv2_super(key = 'rbv2_super', **kwargs):\n",
                "    # Transforms\n",
                "    tfms = {}\n",
                "    [tfms.update({k:ContTransformerRange}) for k in [\"mmce\", \"f1\", \"auc\", \"aknn.k\", \"aknn.M\", \"rpart.maxdepth\", \"rpart.minsplit\", \"rpart.minbucket\", \"xgboost.max_depth\"]]\n",
                "    [tfms.update({k:partial(ContTransformerLogRange)}) for k in [\"timetrain\", \"timepredict\", \"svm.cost\", \"svm.gamma\"]]\n",
                "    [tfms.update({k:partial(ContTransformerLogRange, logfun=torch.log2,  expfun=torch.exp2 )}) for k in [\"glmnet.s\", \"rpart.cp\", \"aknn.ef\", \"aknn.ef_construction\", \"xgboost.nrounds\", \"xgboost.eta\", \"xgboost.gamma\", \"xgboost.lambda\", \"xgboost.alpha\", \"xgboost.min_child_weight\", \"ranger.num.trees\", \"ranger.min.node.size\", 'ranger.num.random.splits']]\n",
                "    [tfms.update({k:ContTransformerNegExpRange}) for k in [\"logloss\"]]\n",
                "\n",
                "    fit_config(key, tfms=tfms, **kwargs)\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "935079f3ab4b06ec76910fd5af9cfadee87e8a756fe17d7789065f69c1782d29"
        },
        "kernelspec": {
            "display_name": "Python 3.9.5 64-bit (conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
